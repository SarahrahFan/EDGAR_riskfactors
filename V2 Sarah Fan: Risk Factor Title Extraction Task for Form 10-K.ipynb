{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNvqj86fu8AOWPr7egZDHEE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Risk Factor Title Extraction Task"],"metadata":{"id":"Ib2mXKBvYtvf"}},{"cell_type":"markdown","source":["Yichun Sarah Fan <br>\n","May 17, 2025\n","\n","---"],"metadata":{"id":"bUby30kgl3tf"}},{"cell_type":"markdown","source":["**Project Summary**\n","\n","This Python script extracts risk factors from the ***Item 1A. Risk Factors*** section of SEC 10-K filings for a panel of 10 unique firms over three years. For each filing, the script identifies and captures all visually emphasized risk factor titles, outputting them in a CSV file with the following columns: CIK, filing year, filing date, reporting date, and RFDTitle.\n","\n","The code consists of two main parts.\n","\n","**1. Initialize pyedgar environment:**\n","   - Prepares the environment and necessary libraries for accessing and parsing SEC EDGAR filings.\n","   - Handles data index setup and imports.\n","\n","**2. EDGAR data extraction:**\n","   - Matches each firm-year with the correct 10-K filing.\n","   - Extracts all accentuated risk factor headings (bold, underlined, or italic) from the Item 1A section.\n","   - Writes all results to a structured CSV file for further analysis.\n","\n","This workflow automates and standardizes the extraction of regulatory risk disclosures, enabling efficient and reproducible data collection for research or business purposes."],"metadata":{"id":"KrcQcceJ0okI"}},{"cell_type":"markdown","source":["## Git setup"],"metadata":{"id":"OTTsvufhHX-X"}},{"cell_type":"code","source":["!git config --global user.name \"SarahrahFan\"\n","!git config --global user.email \"fyc6373@gmail.com\""],"metadata":{"id":"jN4P1oAbHfVZ","executionInfo":{"status":"ok","timestamp":1747500103283,"user_tz":240,"elapsed":209,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["github_username = \"SarahrahFan\"\n","github_token = \"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\"\n","\n","with open(\"/root/.netrc\", \"w\") as f:\n","    f.write(f\"machine github.com\\nlogin {github_username}\\npassword {github_token}\\n\")\n","\n","!chmod 600 /root/.netrc"],"metadata":{"id":"sz-6-PHtNPuo","executionInfo":{"status":"ok","timestamp":1747502158355,"user_tz":240,"elapsed":103,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/RA/Tech\\ test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KaBI4nKbH7o5","executionInfo":{"status":"ok","timestamp":1747503021871,"user_tz":240,"elapsed":5,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"862cbe8b-2e2f-4f95-c96d-ccb63362d828"},"execution_count":133,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/RA/Tech test\n"]}]},{"cell_type":"code","source":["!git init"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1wH013nzJFux","executionInfo":{"status":"ok","timestamp":1747503029706,"user_tz":240,"elapsed":300,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"b60a8b0d-b1d9-4713-dc84-f280274ab0e8"},"execution_count":135,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n","\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n","\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n","\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit branch -m <name>\u001b[m\n","Initialized empty Git repository in /content/drive/MyDrive/RA/Tech test/.git/\n"]}]},{"cell_type":"code","source":["!git remote add origin https://github.com/SarahrahFan/EDGAR_riskfactors.git"],"metadata":{"id":"hqiVYfpeTENT","executionInfo":{"status":"ok","timestamp":1747503040442,"user_tz":240,"elapsed":96,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":136,"outputs":[]},{"cell_type":"code","source":["!git add ."],"metadata":{"id":"foJr4lUrIXk4","executionInfo":{"status":"ok","timestamp":1747502822775,"user_tz":240,"elapsed":809,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":127,"outputs":[]},{"cell_type":"code","source":["!git commit -m \"Initial commit from RA/Tech test\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l5YdUVDHIZYQ","executionInfo":{"status":"ok","timestamp":1747502825807,"user_tz":240,"elapsed":901,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"f2964618-9bb0-4830-c132-9de676dd8750"},"execution_count":128,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 999f0cc] Initial commit from RA/Tech test\n"," 2 files changed, 1 insertion(+), 466727 deletions(-)\n"," rewrite V2 Sarah Fan: Risk Factor Title Extraction Task for Form 10-K.ipynb (98%)\n"," delete mode 100644 pyedgar/indices/form_DEF14A.idx\n"]}]},{"cell_type":"code","source":["!git remote remove origin\n","!git remote add origin https://github.com/SarahrahFan/EDGAR_riskfactors.git"],"metadata":{"id":"GJRM3TCGNi7L","executionInfo":{"status":"ok","timestamp":1747502827604,"user_tz":240,"elapsed":206,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":129,"outputs":[]},{"cell_type":"code","source":["!git rm --cached pyedgar/indices/form_all.idx\n","!git rm --cached pyedgar/indices/form_8-K.idx\n","!git rm --cached pyedgar/indices/form_10-Q.idx\n","\n","!echo \"pyedgar/indices/form_all.idx\" >> .gitignore\n","!echo \"pyedgar/indices/form_8-K.idx\" >> .gitignore\n","!echo \"pyedgar/indices/form_10-Q.idx\" >> .gitignore\n","\n","!git add .gitignore\n","!git commit -m \"Remove large .idx files and ignore them in future\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQ3e3lHGSpWv","executionInfo":{"status":"ok","timestamp":1747502931896,"user_tz":240,"elapsed":1123,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"d92d2c9e-a619-4f10-c749-8ebe26df238d"},"execution_count":131,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: pathspec 'pyedgar/indices/form_all.idx' did not match any files\n","fatal: pathspec 'pyedgar/indices/form_8-K.idx' did not match any files\n","fatal: pathspec 'pyedgar/indices/form_10-Q.idx' did not match any files\n","[main c3c0f72] Remove large .idx files and ignore them in future\n"," 1 file changed, 3 insertions(+)\n"]}]},{"cell_type":"code","source":["!git push -u origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIbPnIKDK3iE","executionInfo":{"status":"ok","timestamp":1747502991478,"user_tz":240,"elapsed":54142,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"e33b7dc3-d307-4f0e-b0c0-4bb1b04a12f0"},"execution_count":132,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 31, done.\n","Counting objects:   3% (1/31)\rCounting objects:   6% (2/31)\rCounting objects:   9% (3/31)\rCounting objects:  12% (4/31)\rCounting objects:  16% (5/31)\rCounting objects:  19% (6/31)\rCounting objects:  22% (7/31)\rCounting objects:  25% (8/31)\rCounting objects:  29% (9/31)\rCounting objects:  32% (10/31)\rCounting objects:  35% (11/31)\rCounting objects:  38% (12/31)\rCounting objects:  41% (13/31)\rCounting objects:  45% (14/31)\rCounting objects:  48% (15/31)\rCounting objects:  51% (16/31)\rCounting objects:  54% (17/31)\rCounting objects:  58% (18/31)\rCounting objects:  61% (19/31)\rCounting objects:  64% (20/31)\rCounting objects:  67% (21/31)\rCounting objects:  70% (22/31)\rCounting objects:  74% (23/31)\rCounting objects:  77% (24/31)\rCounting objects:  80% (25/31)\rCounting objects:  83% (26/31)\rCounting objects:  87% (27/31)\rCounting objects:  90% (28/31)\rCounting objects:  93% (29/31)\rCounting objects:  96% (30/31)\rCounting objects: 100% (31/31)\rCounting objects: 100% (31/31), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (29/29), done.\n","Writing objects: 100% (31/31), 247.81 MiB | 7.26 MiB/s, done.\n","Total 31 (delta 11), reused 1 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (11/11), done.\u001b[K\n","remote: \u001b[1;33mwarning\u001b[m: File pyedgar/indices/form_10-Q.idx is 56.58 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\u001b[K\n","remote: \u001b[1;31merror\u001b[m: Trace: 75486b5414dac87f68f9724c63fe928eaa04ba3fbc12fec06101a1f1213c8dd1\u001b[K\n","remote: \u001b[1;31merror\u001b[m: See https://gh.io/lfs for more information.\u001b[K\n","remote: \u001b[1;31merror\u001b[m: File pyedgar/indices/form_all.idx is 1632.19 MB; this exceeds GitHub's file size limit of 100.00 MB\u001b[K\n","remote: \u001b[1;31merror\u001b[m: File pyedgar/indices/form_8-K.idx is 134.12 MB; this exceeds GitHub's file size limit of 100.00 MB\u001b[K\n","remote: \u001b[1;31merror\u001b[m: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.\u001b[K\n","To https://github.com/SarahrahFan/EDGAR_riskfactors.git\n"," \u001b[31m! [remote rejected]\u001b[m main -> main (pre-receive hook declined)\n","\u001b[31merror: failed to push some refs to 'https://github.com/SarahrahFan/EDGAR_riskfactors.git'\n","\u001b[m"]}]},{"cell_type":"markdown","source":["## Initialize pyedgar environment"],"metadata":{"id":"dQ6ztXzAZE6_"}},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W4Hhw2izU-jZ","executionInfo":{"status":"ok","timestamp":1747490207496,"user_tz":240,"elapsed":667,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"0766f993-bc99-4ef4-84b1-b73d61fe053e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Define and Create pyedgar Directory Structure\n","## Base directory\n","base_dir = '/content/drive/MyDrive/RA/Tech test/pyedgar'\n","\n","## Define subdirectories for config, index, and filings\n","conf_dir = os.path.join(base_dir, 'config')\n","index_dir = os.path.join(base_dir, 'indices')\n","filing_dir = os.path.join(base_dir, 'filings')\n","\n","## Create the directories if they don't exist\n","os.makedirs(conf_dir, exist_ok=True)\n","os.makedirs(index_dir, exist_ok=True)\n","os.makedirs(filing_dir, exist_ok=True)"],"metadata":{"id":"--trIomhXLxD","executionInfo":{"status":"ok","timestamp":1747490208194,"user_tz":240,"elapsed":683,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Create config file\n","conf_path = os.path.join(conf_dir, 'hades.colab.pyedgar.conf')\n","\n","with open(conf_path, 'w') as config_file:\n","    config_file.write(f\"\"\"\n","[DEFAULT]\n","SEC_BASE_URL = https://www.sec.gov\n","HEADERS = Sarah Fan (yichun.fan@gwmail.gwu.edu)\n","\n","[Paths]\n","INDEX_ROOT = {index_dir}\n","FILING_ROOT = {filing_dir}\n","\n","[Index]\n","INDEX_DELIMITER = |\n","INDEX_EXTENSION = idx\n","\n","[Downloader]\n","KEEP_ALL = False\n","\"\"\")\n","\n","# Set Environment Variable\n","os.environ['PYEDGAR_CONF'] = conf_path"],"metadata":{"id":"D-bMkF_VX9b-","executionInfo":{"status":"ok","timestamp":1747490209351,"user_tz":240,"elapsed":1153,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pip install pyedgar"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5mqpCeHeFBPI","executionInfo":{"status":"ok","timestamp":1747490213623,"user_tz":240,"elapsed":4263,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"bf395823-91a8-4274-865f-efdd8f528235"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyedgar\n","  Downloading pyedgar-0.1.13-py3-none-any.whl.metadata (8.9 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pyedgar) (2.2.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pyedgar) (2.32.3)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pyedgar) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pyedgar) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pyedgar) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pyedgar) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pyedgar) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pyedgar) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pyedgar) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pyedgar) (2025.4.26)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pyedgar) (1.17.0)\n","Downloading pyedgar-0.1.13-py3-none-any.whl (52 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.9/52.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pyedgar\n","Successfully installed pyedgar-0.1.13\n"]}]},{"cell_type":"code","source":["from pyedgar import config, Filing, EDGARIndex\n","print(\"‚úÖ pyedgar is using config file from:\", config.CONFIG_FILE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2o8ktcP3fIyY","executionInfo":{"status":"ok","timestamp":1747490215120,"user_tz":240,"elapsed":1499,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"70ba4d1d-f9de-4803-f722-49776703e2ce"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ pyedgar is using config file from: /content/drive/MyDrive/RA/Tech test/pyedgar/config/hades.colab.pyedgar.conf\n"]}]},{"cell_type":"markdown","source":["## EDGAR data extraction"],"metadata":{"id":"ZpB9hA6XZMlW"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"YqXrrFVSQstZ","executionInfo":{"status":"ok","timestamp":1747490215141,"user_tz":240,"elapsed":17,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"outputs":[],"source":["import pandas as pd\n","import re\n","from time import sleep\n","from datetime import datetime\n","from bs4 import BeautifulSoup\n","from dateutil import parser"]},{"cell_type":"code","source":["# Load input file\n","df_input = pd.read_csv(\"/content/drive/MyDrive/RA/Tech test/rasamplemini_rfdtitle.csv\")\n","\n","# Ensure CIK is 10-digit zero-padded (required by EDGARIndex)\n","df_input['cik'] = df_input['cik'].astype(str).str.zfill(10)\n","df_input['filingyear'] = df_input['filingyear'].astype(int)\n","\n","# Load EDGAR index (use cached data if available)\n","idx = EDGARIndex(force_download=False)"],"metadata":{"id":"yv8-XBRfU3T5","executionInfo":{"status":"ok","timestamp":1747490215471,"user_tz":240,"elapsed":324,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import os; [os.remove(v) for k, v in idx.indices.items() if k != 'form_10-K.idx']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xKjYqNcqR2aa","executionInfo":{"status":"ok","timestamp":1747502729664,"user_tz":240,"elapsed":108,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"dbbf42f6-59ff-463a-edde-290c4fe2c052"},"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[None, None, None, None]"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","source":["idx.indices"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yESlU3Y7GsOi","executionInfo":{"status":"ok","timestamp":1747502733700,"user_tz":240,"elapsed":5,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"77d9dad0-d009-457b-c39e-388811b5ca49"},"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'form_10-K.idx': '/content/drive/MyDrive/RA/Tech test/pyedgar/indices/form_10-K.idx'}"]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["index_10k = pd.read_csv('/content/drive/MyDrive/RA/Tech test/pyedgar/indices/form_10-K.idx',\n","                        sep='|', dtype=str, low_memory=False)\n","index_10k['cik'] = index_10k['CIK'].astype(str).str.zfill(10)\n","index_10k['filingyear'] = pd.to_datetime(index_10k['Date Filed'], errors='coerce').dt.year\n","index_10k.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"UI4T7QKzcvU3","executionInfo":{"status":"ok","timestamp":1747490218137,"user_tz":240,"elapsed":2645,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"fc1ad066-1d9a-4fbe-9aed-2d829d5465c7"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  CIK              Company Name Form Type  Date Filed             Accession  \\\n","0  20  K TRON INTERNATIONAL INC      10-K  1996-03-28  0000893220-96-000500   \n","1  20  K TRON INTERNATIONAL INC      10-K  1997-03-19  0000893220-97-000572   \n","2  20  K TRON INTERNATIONAL INC   10-K405  1998-03-18  0000893220-98-000560   \n","3  20  K TRON INTERNATIONAL INC      10-K  1999-03-23  0000893220-99-000357   \n","4  20  K TRON INTERNATIONAL INC   10-K405  2000-03-30  0000893220-00-000394   \n","\n","          cik  filingyear  \n","0  0000000020        1996  \n","1  0000000020        1997  \n","2  0000000020        1998  \n","3  0000000020        1999  \n","4  0000000020        2000  "],"text/html":["\n","  <div id=\"df-93c4be2d-2f77-4281-95fb-053186cbffc1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CIK</th>\n","      <th>Company Name</th>\n","      <th>Form Type</th>\n","      <th>Date Filed</th>\n","      <th>Accession</th>\n","      <th>cik</th>\n","      <th>filingyear</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>20</td>\n","      <td>K TRON INTERNATIONAL INC</td>\n","      <td>10-K</td>\n","      <td>1996-03-28</td>\n","      <td>0000893220-96-000500</td>\n","      <td>0000000020</td>\n","      <td>1996</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20</td>\n","      <td>K TRON INTERNATIONAL INC</td>\n","      <td>10-K</td>\n","      <td>1997-03-19</td>\n","      <td>0000893220-97-000572</td>\n","      <td>0000000020</td>\n","      <td>1997</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20</td>\n","      <td>K TRON INTERNATIONAL INC</td>\n","      <td>10-K405</td>\n","      <td>1998-03-18</td>\n","      <td>0000893220-98-000560</td>\n","      <td>0000000020</td>\n","      <td>1998</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>20</td>\n","      <td>K TRON INTERNATIONAL INC</td>\n","      <td>10-K</td>\n","      <td>1999-03-23</td>\n","      <td>0000893220-99-000357</td>\n","      <td>0000000020</td>\n","      <td>1999</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20</td>\n","      <td>K TRON INTERNATIONAL INC</td>\n","      <td>10-K405</td>\n","      <td>2000-03-30</td>\n","      <td>0000893220-00-000394</td>\n","      <td>0000000020</td>\n","      <td>2000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93c4be2d-2f77-4281-95fb-053186cbffc1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-93c4be2d-2f77-4281-95fb-053186cbffc1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-93c4be2d-2f77-4281-95fb-053186cbffc1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-5cc2791c-8894-48f0-83bd-65982238fced\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5cc2791c-8894-48f0-83bd-65982238fced')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-5cc2791c-8894-48f0-83bd-65982238fced button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"index_10k"}},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### 10-K index check"],"metadata":{"id":"FN-XVmC0yqzY"}},{"cell_type":"code","source":["# Merge to check which targets are matched in the 10-K index\n","check = df_input.merge(\n","    index_10k[['cik', 'filingyear', 'Accession']],\n","    on=['cik', 'filingyear'],\n","    how='left',\n","    indicator=True\n",")\n","\n","# Print summary\n","n_total = len(df_input)\n","n_matched = (check['_merge'] == 'both').sum()\n","n_missing = (check['_merge'] == 'left_only').sum()\n","\n","print(f\"Total CIK-year pairs: {n_total}\")\n","print(f\"Matched in 10-K index: {n_matched}\")\n","print(f\"Missing in 10-K index: {n_missing}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"stLZo9gEvJop","executionInfo":{"status":"ok","timestamp":1747490218561,"user_tz":240,"elapsed":422,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"f6311e27-621a-4bd9-f024-d70fb1691822"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Total CIK-year pairs: 30\n","Matched in 10-K index: 36\n","Missing in 10-K index: 0\n"]}]},{"cell_type":"code","source":["# Count how many unique 10-K accessions exist for each (cik, filingyear) pair\n","dupes = check[check['_merge'] == 'both'] \\\n","    .groupby(['cik', 'filingyear'])['Accession'] \\\n","    .nunique() \\\n","    .reset_index()\n","\n","# Keep only those cik+filingyear pairs with more than one 10-K accession\n","dupes = dupes[dupes['Accession'] > 1]\n","\n","print(f\"Number of company/year pairs with multiple 10-Ks: {len(dupes)}\")\n","print(dupes)\n","\n","# Optionally: List all accessions for these cik+year pairs for inspection\n","if not dupes.empty:\n","    # Merge with original data to display all matching accessions\n","    details = check.merge(dupes[['cik', 'filingyear']], on=['cik', 'filingyear'], how='inner')\n","    print(\"\\nDetailed duplicate records:\")\n","    print(details[['cik', 'filingyear', 'Accession']].sort_values(['cik', 'filingyear']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHJEfAt7w8o4","executionInfo":{"status":"ok","timestamp":1747490218691,"user_tz":240,"elapsed":128,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"a69f6329-d3d4-4a88-d4fc-600e80540668"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of company/year pairs with multiple 10-Ks: 6\n","           cik  filingyear  Accession\n","8   0000002034        2017          2\n","12  0000003116        2013          2\n","14  0000003116        2015          2\n","17  0000004962        2012          2\n","25  0000006201        2006          2\n","26  0000006201        2007          2\n","\n","Detailed duplicate records:\n","           cik  filingyear             Accession\n","0   0000002034        2017  0001144204-17-045100\n","1   0000002034        2017  0001144204-17-057835\n","4   0000003116        2013  0001157523-13-001183\n","5   0000003116        2013  0001157523-13-001479\n","2   0000003116        2015  0001171843-15-001465\n","3   0000003116        2015  0001171843-15-002393\n","6   0000004962        2012  0001193125-12-077400\n","7   0000004962        2012  0001140361-12-011832\n","10  0000006201        2006  0000950134-06-003715\n","11  0000006201        2006  0000006201-06-000049\n","8   0000006201        2007  0000950134-07-003888\n","9   0000006201        2007  0000950134-07-004263\n"]}]},{"cell_type":"markdown","source":["Based on the results above, manual inspection confirms that all duplicate records are due to amended filings (such as revised or supplemental reports). For subsequent analysis, we will use the most recent version, specifically the ‚ÄúFORM 10-K/A‚Äù filings, for each CIK-year pair where duplicates exist."],"metadata":{"id":"P3EzA3GLx4Qb"}},{"cell_type":"code","source":["# Keep only target cik + filingyear pairs from your input list\n","targets = df_input[['cik', 'filingyear']].drop_duplicates()\n","\n","# Merge all 10-K index entries with the target cik + filingyear pairs\n","merged = index_10k.merge(targets, on=['cik', 'filingyear'], how='inner')\n","\n","# Sort by cik, filingyear, Date Filed (ascending), and Accession (ascending)\n","merged['Date Filed'] = pd.to_datetime(merged['Date Filed'], errors='coerce')\n","merged = merged.sort_values(['cik', 'filingyear', 'Date Filed', 'Accession'])\n","\n","# For each (cik, filingyear) group, keep only the latest record (last one in the sorted group)\n","latest = merged.groupby(['cik', 'filingyear'], as_index=False).last()\n","\n","# Display the selected records: one most recent 10-K per cik and year\n","print(latest[['cik', 'filingyear', 'Accession', 'Date Filed', 'Form Type']])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mvGt2_kc1cNs","executionInfo":{"status":"ok","timestamp":1747490218901,"user_tz":240,"elapsed":193,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"09c8a91b-6659-4d5b-ba27-5cdf2835e426"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["           cik  filingyear             Accession Date Filed Form Type\n","0   0000001750        2016  0001047469-16-014299 2016-07-13      10-K\n","1   0000001750        2017  0001047469-17-004528 2017-07-12      10-K\n","2   0000001750        2018  0001047469-18-004978 2018-07-11      10-K\n","3   0000001800        2015  0001047469-15-001377 2015-02-27      10-K\n","4   0000001800        2016  0001047469-16-010246 2016-02-19      10-K\n","5   0000001800        2017  0001047469-17-000744 2017-02-17      10-K\n","6   0000002034        2015  0001571049-15-007509 2015-09-11      10-K\n","7   0000002034        2016  0001571049-16-017785 2016-08-26      10-K\n","8   0000002034        2017  0001144204-17-057835 2017-11-09    10-K/A\n","9   0000002488        2008  0001193125-08-038588 2008-02-26      10-K\n","10  0000002488        2009  0001193125-09-036235 2009-02-24      10-K\n","11  0000002488        2010  0001193125-10-035218 2010-02-19      10-K\n","12  0000003116        2013  0001157523-13-001479 2013-03-20    10-K/A\n","13  0000003116        2014  0001157523-14-001078 2014-03-14      10-K\n","14  0000003116        2015  0001171843-15-002393 2015-04-30    10-K/A\n","15  0000004962        2010  0001193125-10-041232 2010-02-26      10-K\n","16  0000004962        2011  0000950123-11-019072 2011-02-28      10-K\n","17  0000004962        2012  0001140361-12-011832 2012-02-29    10-K/A\n","18  0000004977        2007  0001104659-07-015014 2007-02-28      10-K\n","19  0000004977        2008  0000950144-08-001495 2008-02-29      10-K\n","20  0000004977        2009  0000950144-09-001463 2009-02-20      10-K\n","21  0000005768        2007  0001104659-07-047514 2007-06-13      10-K\n","22  0000005768        2008  0001104659-08-039830 2008-06-13      10-K\n","23  0000005768        2009  0001104659-09-038109 2009-06-15      10-K\n","24  0000006201        2005  0000950134-05-003726 2005-02-25      10-K\n","25  0000006201        2006  0000006201-06-000049 2006-07-17    10-K/A\n","26  0000006201        2007  0000950134-07-004263 2007-02-27    10-K/A\n","27  0000006720        2005  0001193125-05-052635 2005-03-16      10-K\n","28  0000006720        2006  0001193125-06-056413 2006-03-16      10-K\n","29  0000006720        2007  0001193125-07-056201 2007-03-16      10-K\n"]}]},{"cell_type":"markdown","source":["### Functions"],"metadata":{"id":"Jhbhf5NlI0eK"}},{"cell_type":"markdown","source":["#### Extraciton for reporting date\n"],"metadata":{"id":"uaA2X-KQ42EY"}},{"cell_type":"code","source":["def extract_reporting_date_from_html(html, maxlen=6000):\n","    html_head = html[:maxlen]\n","    html_head = html_head.replace('&nbsp;', ' ').replace('&#160;', ' ').replace('\\xa0', ' ')\n","\n","    # Step 1: Look directly in HTML for the date pattern\n","    m = re.search(\n","        r'(?i)for\\s+(?:the\\s+)?(?:fiscal\\s+)?year\\s+ended\\s+([A-Za-z]{3,10})\\s*\\.?\\s*(\\d{1,2}),?\\s*(\\d{4})',\n","        html_head\n","    )\n","    if m:\n","        # Combine month, day, year\n","        date_str = f\"{m.group(1)} {m.group(2)}, {m.group(3)}\"\n","        try:\n","            dt = parser.parse(date_str)\n","            return dt.strftime(\"%Y/%m/%d\")\n","        except Exception as e:\n","            print(\"‚ùå Failed to parse:\", date_str, \"| Error:\", e)\n","\n","    # Step 2: Fallback to <PERIOD> tag\n","    m = re.search(r\"<PERIOD>(\\d{8})</PERIOD>\", html_head, re.IGNORECASE)\n","    if m:\n","        date = m.group(1)\n","        print(\"üìÑ Found <PERIOD>:\", date)\n","        return f\"{date[:4]}/{date[4:6]}/{date[6:]}\"\n","\n","    m = re.search(r\"PERIOD[=:\\s]+(\\d{8})\", html_head, re.IGNORECASE)\n","    if m:\n","        date = m.group(1)\n","        print(\"üìÑ Found PERIOD=:\", date)\n","        return f\"{date[:4]}/{date[4:6]}/{date[6:]}\"\n","\n","    print(f\"‚ö†Ô∏è No reporting date found for CIK={cik}, Year={year}\")\n","    return \"\""],"metadata":{"id":"DrIkB74kJeUt","executionInfo":{"status":"ok","timestamp":1747496579911,"user_tz":240,"elapsed":36,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["#### Extraction for risk factors section"],"metadata":{"id":"MTRuJ9OkJCd5"}},{"cell_type":"code","source":["def extract_item_1a_section_from_html(txt, cik=None, year=None):\n","    txt = txt.replace('&nbsp;', ' ').replace('&#160;', ' ').replace('\\xa0', ' ')\n","\n","    # Step 1: Try direct match: \"Item 1A ... Risk Factors ... Item 1B/2\"\n","    pattern = r'(item\\s*1a[\\.\\:]*.*?risk\\s*factors.*?)(item\\s*1b|item\\s*2|signatures)'\n","    matches = re.findall(pattern, txt, flags=re.IGNORECASE | re.DOTALL | re.MULTILINE)\n","    if matches:\n","        print(f\"‚úÖ Found Item 1A section for CIK={cik}, Year={year} (direct match)\")\n","        return max(matches, key=lambda x: len(x[0]))[0]\n","\n","    # Step 2: Fallback - check <tr> with split \"Item 1A\" and \"Risk Factors\"\n","    tr_blocks = re.findall(r'<tr.*?>.*?</tr>', txt, flags=re.IGNORECASE | re.DOTALL)\n","    for block in tr_blocks:\n","        if re.search(r'item\\s*1a', block, re.IGNORECASE) and re.search(r'risk\\s*factors', block, re.IGNORECASE):\n","            print(f\"üîé Found split-tag header (Item 1A and Risk Factors in separate TDs) for CIK={cik}, Year={year}\")\n","            start_index = txt.find(block)\n","            txt_trimmed = txt[start_index:]\n","            matches = re.findall(pattern, txt_trimmed, flags=re.IGNORECASE | re.DOTALL | re.MULTILINE)\n","            if matches:\n","                print(f\"‚úÖ Found Item 1A section for CIK={cik}, Year={year} (via fallback)\")\n","                return max(matches, key=lambda x: len(x[0]))[0]\n","            else:\n","                print(f\"‚ö†Ô∏è Split header found but no full Item 1A block matched for CIK={cik}, Year={year}\")\n","            break\n","\n","    # Step 3: Fallback - <B>Risk Factors</B> ... until ITEM 7 or ITEM 7A\n","    alt_patterns = [\n","        r'<b>\\s*risk\\s*factors\\s*</b>',\n","        r'<b>\\s*factors\\s+that\\s+could\\s+affect\\s+future\\s+results\\s*</b>'\n","    ]\n","    for alt_start in alt_patterns:\n","        m_start = re.search(alt_start, txt, flags=re.IGNORECASE)\n","        if m_start:\n","            start = m_start.start()\n","            m_end = re.search(r'item\\s*7\\s*(a)?[\\.\\:]', txt[start:], flags=re.IGNORECASE)\n","            end = start + m_end.start() if m_end else len(txt)\n","            print(f\"üü° Found alternate Risk Factor section for CIK={cik}, Year={year}\")\n","            return txt[start:end]\n","\n","    print(f\"‚ùå Item 1A section not found for CIK={cik}, Year={year}\")\n","    return None"],"metadata":{"id":"jV8QbIBy5vMF","executionInfo":{"status":"ok","timestamp":1747498277299,"user_tz":240,"elapsed":5,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["def extract_item_1a_section_from_html(txt, cik=None, year=None):\n","    txt = txt.replace('&nbsp;', ' ').replace('&#160;', ' ').replace('\\xa0', ' ')\n","\n","    # Step 1: Direct match\n","    pattern = r'(item\\s*1a[\\.\\:]*.*?risk\\s*factors.*?)(item\\s*1b|item\\s*2|signatures)'\n","    matches = re.findall(pattern, txt, flags=re.IGNORECASE | re.DOTALL | re.MULTILINE)\n","    if matches:\n","        print(f\"‚úÖ Found Item 1A section for CIK={cik}, Year={year} (direct match)\")\n","        return max(matches, key=lambda x: len(x[0]))[0], \"direct\"\n","\n","    # Step 2: split <tr> fallback\n","    tr_blocks = re.findall(r'<tr.*?>.*?</tr>', txt, flags=re.IGNORECASE | re.DOTALL)\n","    for block in tr_blocks:\n","        if re.search(r'item\\s*1a', block, re.IGNORECASE) and re.search(r'risk\\s*factors', block, re.IGNORECASE):\n","            print(f\"üîé Found split-tag header for CIK={cik}, Year={year}\")\n","            start_index = txt.find(block)\n","            txt_trimmed = txt[start_index:]\n","            matches = re.findall(pattern, txt_trimmed, flags=re.IGNORECASE | re.DOTALL | re.MULTILINE)\n","            if matches:\n","                print(f\"‚úÖ Found Item 1A section via fallback for CIK={cik}, Year={year}\")\n","                return max(matches, key=lambda x: len(x[0]))[0], \"split-tr\"\n","            break\n","\n","    # Step 3: fallback to Risk Factors heading before Item 7\n","    alt_patterns = [\n","        r'<b>\\s*risk\\s*factors\\s*</b>',\n","        r'<b>\\s*factors\\s+that\\s+could\\s+affect\\s+future\\s+results\\s*</b>'\n","    ]\n","    for alt_start in alt_patterns:\n","        m_start = re.search(alt_start, txt, flags=re.IGNORECASE)\n","        if m_start:\n","            start = m_start.start()\n","            m_end = re.search(r'item\\s*7\\s*(a)?[\\.\\:]', txt[start:], flags=re.IGNORECASE)\n","            end = start + m_end.start() if m_end else len(txt)\n","            print(f\"üü° Fallback: Risk Factors before Item 7 for CIK={cik}, Year={year}\")\n","            return txt[start:end], \"item7-fallback\"\n","\n","    print(f\"‚ùå Item 1A section not found for CIK={cik}, Year={year}\")\n","    return None, None"],"metadata":{"id":"EU1d96l4CiMH","executionInfo":{"status":"ok","timestamp":1747498707964,"user_tz":240,"elapsed":15,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":["#### Extraction for titles"],"metadata":{"id":"o6G0cU9S55_A"}},{"cell_type":"code","source":["def extract_risk_titles_from_item_1a_html(risk_html):\n","    if not risk_html:\n","        return []\n","\n","    soup = BeautifulSoup(risk_html, \"html.parser\")\n","    candidates = []\n","\n","    for tag in soup.find_all(['b', 'i']):\n","        sub = tag.get_text(separator=' ', strip=True)\n","\n","        # Remove non-breaking spaces left after HTML parsing\n","        sub = sub.replace('\\xa0', ' ')\n","\n","        if (\n","            sub\n","            and not re.search(r'item\\s*1a', sub, re.IGNORECASE)\n","            and not re.search(r'risk factors?', sub, re.IGNORECASE)\n","            and not sub.endswith(':')\n","            and not sub.isupper()\n","        ):\n","            candidates.append(sub)\n","\n","    # Deduplicate while preserving order\n","    deduped = list(dict.fromkeys(candidates))\n","\n","    # Print number of titles found\n","    print(f\"‚úÖ Total risk factor titles found: {len(deduped)}\")\n","\n","    return list(dict.fromkeys(candidates))"],"metadata":{"id":"o7I_As7q59Nv","executionInfo":{"status":"ok","timestamp":1747497994074,"user_tz":240,"elapsed":40,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":66,"outputs":[]},{"cell_type":"markdown","source":["### Extraction output"],"metadata":{"id":"Ns9FVwg9I9yB"}},{"cell_type":"markdown","source":["#### Reportingdate output check"],"metadata":{"id":"7tVogCqL10fH"}},{"cell_type":"code","source":["reporting_records = []\n","\n","for row in df_input.itertuples(index=False):\n","    cik = str(row.cik).zfill(10)\n","    year = int(row.filingyear)\n","\n","    df_cik_match = index_10k[\n","        (index_10k['CIK'].astype(str).str.zfill(10) == cik) &\n","        (pd.to_datetime(index_10k['Date Filed']).dt.year == year)\n","    ]\n","    if df_cik_match.empty:\n","        continue\n","\n","    filing_meta = df_cik_match.iloc[0]\n","    accession = filing_meta['Accession'].split('/')[-1].replace('.txt', '')\n","    filingdate = filing_meta['Date Filed']\n","\n","    try:\n","        filing = Filing(cik=cik, accession=accession)\n","        text = filing.full_text\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è Failed to retrieve filing text for {cik}, {accession}: {e}\")\n","        continue\n","\n","    reportingdate = extract_reporting_date_from_html(text)\n","\n","    reporting_records.append({\n","        'cik': cik,\n","        'filingyear': year,\n","        'filingdate': filingdate,\n","        'reportingdate': reportingdate\n","    })\n","\n","df_reporting = pd.DataFrame(reporting_records)\n","print(df_reporting)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3--Am48J16Cj","executionInfo":{"status":"ok","timestamp":1747495669979,"user_tz":240,"elapsed":13210,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"116e3227-116a-4d8d-a3a4-174a3e199fbb"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["           cik  filingyear  filingdate reportingdate\n","0   0000001750        2018  2018-07-11    2018/05/31\n","1   0000001750        2017  2017-07-12    2017/05/31\n","2   0000001750        2016  2016-07-13    2016/05/31\n","3   0000001800        2017  2017-02-17    2016/12/31\n","4   0000001800        2016  2016-02-19    2015/12/31\n","5   0000001800        2015  2015-02-27    2014/12/31\n","6   0000002034        2017  2017-08-25    2017/06/30\n","7   0000002034        2016  2016-08-26    2016/06/30\n","8   0000002034        2015  2015-09-11    2015/06/30\n","9   0000002488        2010  2010-02-19    2009/12/26\n","10  0000002488        2009  2009-02-24    2008/12/27\n","11  0000002488        2008  2008-02-26    2007/12/29\n","12  0000003116        2015  2015-03-17    2014/12/31\n","13  0000003116        2014  2014-03-14    2013/12/31\n","14  0000003116        2013  2013-03-01    2012/12/31\n","15  0000004962        2012  2012-02-24    2011/12/31\n","16  0000004962        2011  2011-02-28    2010/12/31\n","17  0000004962        2010  2010-02-26    2009/12/31\n","18  0000004977        2009  2009-02-20    2008/12/31\n","19  0000004977        2008  2008-02-29    2007/12/31\n","20  0000004977        2007  2007-02-28    2006/12/31\n","21  0000005768        2009  2009-06-15    2009/03/31\n","22  0000005768        2008  2008-06-13    2008/03/31\n","23  0000005768        2007  2007-06-13    2007/03/31\n","24  0000006201        2007  2007-02-23    2006/12/31\n","25  0000006201        2006  2006-02-24    2005/12/31\n","26  0000006201        2005  2005-02-25    2004/12/31\n","27  0000006720        2007  2007-03-16    2006/12/31\n","28  0000006720        2006  2006-03-16    2005/12/31\n","29  0000006720        2005  2005-03-16    2004/12/31\n"]}]},{"cell_type":"markdown","source":["#### Risk factors section check"],"metadata":{"id":"Utd82CDg28s5"}},{"cell_type":"code","source":["item1a_check = []\n","\n","for row in df_reporting.itertuples(index=False):\n","    cik = str(row.cik).zfill(10)\n","    year = int(row.filingyear)\n","    filingdate = row.filingdate\n","\n","    df_cik_match = index_10k[\n","        (index_10k['CIK'].astype(str).str.zfill(10) == cik) &\n","        (pd.to_datetime(index_10k['Date Filed']).dt.year == year)\n","    ]\n","    if df_cik_match.empty:\n","        continue\n","\n","    accession = df_cik_match.iloc[0]['Accession'].split('/')[-1].replace('.txt', '')\n","\n","    try:\n","        filing = Filing(cik=cik, accession=accession)\n","        text = filing.full_text\n","    except Exception as e:\n","        print(f\"‚ö†Ô∏è Failed to retrieve filing text for {cik}, {accession}: {e}\")\n","        continue\n","\n","    # Step 1A: check for presence of Item 1A block\n","    risk_html = extract_item_1a_section_from_html(text, cik=cik, year=year)\n","    status = \"‚úÖ Found\" if risk_html else \"‚ùå Not found\"\n","\n","    item1a_check.append({\n","        'cik': cik,\n","        'filingyear': year,\n","        'filingdate': filingdate,\n","        'item_1a_found': status\n","    })\n","\n","df_check = pd.DataFrame(item1a_check)\n","print(df_check.head(10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4iZkxrj6XtC","executionInfo":{"status":"ok","timestamp":1747498739227,"user_tz":240,"elapsed":26954,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"160b1f8e-747f-46a8-f607-50b850799c06"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Found Item 1A section for CIK=0000001750, Year=2018 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000001750, Year=2017 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000001750, Year=2016 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000001800, Year=2017 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000001800, Year=2016 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000001800, Year=2015 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000002034, Year=2017 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000002034, Year=2016 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000002034, Year=2015 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000002488, Year=2010 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000002488, Year=2009 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000002488, Year=2008 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000003116, Year=2015 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000003116, Year=2014 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000003116, Year=2013 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000004962, Year=2012 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000004962, Year=2011 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000004962, Year=2010 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000004977, Year=2009 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000004977, Year=2008 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000004977, Year=2007 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000005768, Year=2009 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000005768, Year=2008 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000005768, Year=2007 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000006201, Year=2007 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000006201, Year=2006 (direct match)\n","üü° Fallback: Risk Factors before Item 7 for CIK=0000006201, Year=2005\n","‚úÖ Found Item 1A section for CIK=0000006720, Year=2007 (direct match)\n","‚úÖ Found Item 1A section for CIK=0000006720, Year=2006 (direct match)\n","üü° Fallback: Risk Factors before Item 7 for CIK=0000006720, Year=2005\n","          cik  filingyear  filingdate item_1a_found\n","0  0000001750        2018  2018-07-11       ‚úÖ Found\n","1  0000001750        2017  2017-07-12       ‚úÖ Found\n","2  0000001750        2016  2016-07-13       ‚úÖ Found\n","3  0000001800        2017  2017-02-17       ‚úÖ Found\n","4  0000001800        2016  2016-02-19       ‚úÖ Found\n","5  0000001800        2015  2015-02-27       ‚úÖ Found\n","6  0000002034        2017  2017-08-25       ‚úÖ Found\n","7  0000002034        2016  2016-08-26       ‚úÖ Found\n","8  0000002034        2015  2015-09-11       ‚úÖ Found\n","9  0000002488        2010  2010-02-19       ‚úÖ Found\n"]}]},{"cell_type":"markdown","source":["#### Risk titles output"],"metadata":{"id":"tTa7n2W46TYv"}},{"cell_type":"code","source":["rfd_records = []\n","\n","for row in islice(df_reporting.itertuples(index=False), 6, 7):  # ‰ªÖÂèñÁ¨¨7Êù°Êï∞ÊçÆ\n","    cik = str(row.cik).zfill(10)\n","    year = int(row.filingyear)\n","    filingdate = row.filingdate\n","\n","    df_cik_match = index_10k[\n","        (index_10k['CIK'].astype(str).str.zfill(10) == cik) &\n","        (pd.to_datetime(index_10k['Date Filed']).dt.year == year)\n","    ]\n","    if df_cik_match.empty:\n","        continue\n","\n","    accession = df_cik_match.iloc[0]['Accession'].split('/')[-1].replace('.txt', '')\n","\n","    try:\n","        filing = Filing(cik=cik, accession=accession)\n","        text = filing.full_text\n","    except Exception:\n","        print(f\"‚ö†Ô∏è Failed to load filing for CIK={cik}, Accession={accession}\")\n","        continue\n","\n","    # ÊèêÂèñ Item 1A ÂÜÖÂÆπ + Êù•Ê∫êÊ†áËØÜ\n","    risk_html, source = extract_item_1a_section_from_html(text, cik=cik, year=year)\n","\n","    if not risk_html:\n","        continue\n","\n","    # ÊèêÂèñÂ∞èÊ†áÈ¢ò\n","    risk_titles = extract_risk_titles_from_item_1a_html(risk_html)\n","\n","    if not risk_titles:\n","        risk_titles = ['']\n","\n","    for title in risk_titles:\n","        rfd_records.append({\n","            'cik': cik,\n","            'filingyear': year,\n","            'filingdate': filingdate,\n","            'source': source,\n","            'RFDTitle': title.strip()\n","        })\n","\n","# ÊûÑÂª∫ DataFrame\n","df_rfd = pd.DataFrame(rfd_records)\n","print(df_rfd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2VrSwSw76YLi","executionInfo":{"status":"ok","timestamp":1747498795212,"user_tz":240,"elapsed":688,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"765b3b9b-9174-48dd-c386-4b97075736ad"},"execution_count":79,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Found Item 1A section for CIK=0000002034, Year=2017 (direct match)\n","‚úÖ Total risk factor titles found: 77\n","           cik  filingyear  filingdate  source  \\\n","0   0000002034        2017  2017-08-25  direct   \n","1   0000002034        2017  2017-08-25  direct   \n","2   0000002034        2017  2017-08-25  direct   \n","3   0000002034        2017  2017-08-25  direct   \n","4   0000002034        2017  2017-08-25  direct   \n","..         ...         ...         ...     ...   \n","72  0000002034        2017  2017-08-25  direct   \n","73  0000002034        2017  2017-08-25  direct   \n","74  0000002034        2017  2017-08-25  direct   \n","75  0000002034        2017  2017-08-25  direct   \n","76  0000002034        2017  2017-08-25  direct   \n","\n","                                             RFDTitle  \n","0                                    Item 1. Business  \n","1                                        Human Health  \n","2                          Pharmaceutical Ingredients  \n","3   Outlook for Global Medicines Through 2021: Bal...  \n","4                               Performance Chemicals  \n","..                                                ...  \n","72  There are inherent uncertainties involved\\nin ...  \n","73  Changes in accounting standards issued\\nby the...  \n","74  Failure to maintain effective internal\\ncontro...  \n","75  Compliance with changing regulation\\nof corpor...  \n","76  The expansion of social media platforms\\nprese...  \n","\n","[77 rows x 5 columns]\n"]}]},{"cell_type":"markdown","source":["### Final output"],"metadata":{"id":"ANvaZT6S6RpD"}},{"cell_type":"code","source":["# test\n","df_rfd.to_csv('risk_titles.csv', index=False)"],"metadata":{"id":"aZVzsymRnxuM","executionInfo":{"status":"ok","timestamp":1747498816988,"user_tz":240,"elapsed":42,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":["## Reference"],"metadata":{"id":"z5AxLnB62C5k"}},{"cell_type":"markdown","source":["Campbell, J. L., Chen, H., Dhaliwal, D. S., Lu, H. M., & Steele, L. B. (2014). The information content of mandatory risk factor disclosures in corporate filings. *Review of Accounting Studies, 19*(1), 396‚Äì455.\n","\n","Gaulin, M. P. (2017). *Risk fact or fiction: The information content of risk factor disclosures* (Doctoral dissertation, Rice University).\n"],"metadata":{"id":"2O61f9ZH2EqS"}}]}