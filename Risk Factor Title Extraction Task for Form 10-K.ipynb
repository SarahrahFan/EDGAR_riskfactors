{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPJsCQWcmKQOrU9n4apTLNa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Risk Factor Title Extraction Task"],"metadata":{"id":"Ib2mXKBvYtvf"}},{"cell_type":"markdown","source":["Yichun Sarah Fan <br>\n","May 19, 2025\n","\n","---"],"metadata":{"id":"bUby30kgl3tf"}},{"cell_type":"markdown","source":["**Project Summary**\n","\n","This Python script extracts risk factors from the ***Item 1A. Risk Factors*** section of SEC 10-K filings for a panel of 10 unique firms over three years. For each filing, the script identifies and captures all visually emphasized risk factor titles, outputting them in a CSV file with the following columns: CIK, filing year, filing date, reporting date, and RFDTitle.\n","\n","The code consists of two main parts.\n","\n","**1. Initialize pyedgar environment:**\n","   - Prepares the environment and necessary libraries for accessing and parsing SEC EDGAR filings.\n","   - Handles data index setup and imports.\n","\n","**2. EDGAR data extraction:**\n","   - Matches each firm-year with the correct 10-K filing.\n","   - Extracts all accentuated risk factor headings (bold, underlined, or italic) from the Item 1A section.\n","   - Writes all results to a structured CSV file for further analysis.\n","\n","This workflow automates and standardizes the extraction of regulatory risk disclosures, enabling efficient and reproducible data collection for research or business purposes."],"metadata":{"id":"KrcQcceJ0okI"}},{"cell_type":"markdown","source":["## Git setup"],"metadata":{"id":"OTTsvufhHX-X"}},{"cell_type":"code","source":["!git config --global user.name \"SarahrahFan\"\n","!git config --global user.email \"fyc6373@gmail.com\""],"metadata":{"id":"jN4P1oAbHfVZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["github_username = \"SarahrahFan\"\n","github_token = \"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\"\n","\n","with open(\"/root/.netrc\", \"w\") as f:\n","    f.write(f\"machine github.com\\nlogin {github_username}\\npassword {github_token}\\n\")\n","\n","!chmod 600 /root/.netrc"],"metadata":{"id":"sz-6-PHtNPuo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/RA/Tech\\ test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KaBI4nKbH7o5","executionInfo":{"status":"ok","timestamp":1747510349941,"user_tz":240,"elapsed":43,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"7988fdae-02d5-4f60-af6e-7071627cc6d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/RA/Tech test\n"]}]},{"cell_type":"code","source":["!git init"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1wH013nzJFux","executionInfo":{"status":"ok","timestamp":1747503029706,"user_tz":240,"elapsed":300,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"b60a8b0d-b1d9-4713-dc84-f280274ab0e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n","\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n","\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n","\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n","\u001b[33mhint: \u001b[m\n","\u001b[33mhint: \tgit branch -m <name>\u001b[m\n","Initialized empty Git repository in /content/drive/MyDrive/RA/Tech test/.git/\n"]}]},{"cell_type":"code","source":["!git remote add origin https://github.com/SarahrahFan/EDGAR_riskfactors.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqiVYfpeTENT","executionInfo":{"status":"ok","timestamp":1747510445560,"user_tz":240,"elapsed":101,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"01be6909-f01e-4a5f-c491-a337fd534f3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["error: remote origin already exists.\n"]}]},{"cell_type":"code","source":["!echo \"pyedgar/indices/form_all.idx\" >> .gitignore\n","!echo \"pyedgar/indices/form_8-K.idx\" >> .gitignore\n","!echo \"pyedgar/indices/form_10-Q.idx\" >> .gitignore\n","\n","!git add .\n","!git commit -m \"Clean initial commit without large files\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQ3e3lHGSpWv","executionInfo":{"status":"ok","timestamp":1747503113640,"user_tz":240,"elapsed":1523,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"94252b35-5a50-4530-f4b2-f7bb2030ccae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[master (root-commit) ef1c736] Clean initial commit without large files\n"," 7 files changed, 355923 insertions(+)\n"," create mode 100644 .gitignore\n"," create mode 100644 Sarah Fan: Risk Factor Title Extraction Task for Form 10-K.ipynb\n"," create mode 100644 V2 Sarah Fan: Risk Factor Title Extraction Task for Form 10-K.ipynb\n"," create mode 100644 pyedgar/config/hades.colab.pyedgar.conf\n"," create mode 100644 pyedgar/indices/form_10-K.idx\n"," create mode 100644 rasamplemini_rfdtitle.csv\n"," create mode 100644 submit_Sarah_Fan_Risk_Factor_Title_Extraction_Task_for_Form_10_K.ipynb\n"]}]},{"cell_type":"code","source":["!git branch -M main\n","!git push -u --force origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIbPnIKDK3iE","executionInfo":{"status":"ok","timestamp":1747503207698,"user_tz":240,"elapsed":4412,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"a6dda6e5-4d3a-4364-ba73-0da66de89e98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 12, done.\n","Counting objects:   8% (1/12)\rCounting objects:  16% (2/12)\rCounting objects:  25% (3/12)\rCounting objects:  33% (4/12)\rCounting objects:  41% (5/12)\rCounting objects:  50% (6/12)\rCounting objects:  58% (7/12)\rCounting objects:  66% (8/12)\rCounting objects:  75% (9/12)\rCounting objects:  83% (10/12)\rCounting objects:  91% (11/12)\rCounting objects: 100% (12/12)\rCounting objects: 100% (12/12), done.\n","Delta compression using up to 2 threads\n","Compressing objects: 100% (11/11), done.\n","Writing objects: 100% (12/12), 4.33 MiB | 2.34 MiB/s, done.\n","Total 12 (delta 1), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas: 100% (1/1), done.\u001b[K\n","To https://github.com/SarahrahFan/EDGAR_riskfactors.git\n"," * [new branch]      main -> main\n","Branch 'main' set up to track remote branch 'main' from 'origin'.\n"]}]},{"cell_type":"markdown","source":["## Git update"],"metadata":{"id":"qJNgzUjAunhw"}},{"cell_type":"code","source":["!git status"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xjs1ih5cupyA","executionInfo":{"status":"ok","timestamp":1747709136943,"user_tz":240,"elapsed":101,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"1877a103-e73e-496c-c564-32143b69d0ee"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: not a git repository (or any of the parent directories): .git\n"]}]},{"cell_type":"code","source":["!git add ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nQUk6M0Nutcl","executionInfo":{"status":"ok","timestamp":1747510360124,"user_tz":240,"elapsed":1555,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"95d9b097-6c63-4f6d-a636-d016a827d033"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 1649c66] Update [file/module]: improved Item 1A extraction and handling notes\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite V2 Sarah Fan: Risk Factor Title Extraction Task for Form 10-K.ipynb (87%)\n"]}]},{"cell_type":"code","source":["!git commit -m \"Optimize extraction logic: added character limit, special character cleanup, footnote handling, and table of contents distinction\""],"metadata":{"id":"9EwyEjmai7u3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git push"],"metadata":{"id":"-KJOMQVPitH7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !git push origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I9tNLqpPwJd_","executionInfo":{"status":"ok","timestamp":1747510880332,"user_tz":240,"elapsed":1126,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"3fd349e1-67ff-4e3f-e693-2929d59f9547"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enumerating objects: 5, done.\n","Counting objects:  20% (1/5)\rCounting objects:  40% (2/5)\rCounting objects:  60% (3/5)\rCounting objects:  80% (4/5)\rCounting objects: 100% (5/5)\rCounting objects: 100% (5/5), done.\n","Delta compression using up to 2 threads\n","Compressing objects:  33% (1/3)\rCompressing objects:  66% (2/3)\rCompressing objects: 100% (3/3)\rCompressing objects: 100% (3/3), done.\n","Writing objects:  33% (1/3)\rWriting objects:  66% (2/3)\rWriting objects: 100% (3/3)\rWriting objects: 100% (3/3), 6.23 KiB | 455.00 KiB/s, done.\n","Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n","remote: Resolving deltas:   0% (0/2)\u001b[K\rremote: Resolving deltas:  50% (1/2)\u001b[K\rremote: Resolving deltas: 100% (2/2)\u001b[K\rremote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To github.com:SarahrahFan/EDGAR_riskfactors.git\n","   ef1c736..1649c66  main -> main\n"]}]},{"cell_type":"markdown","source":["## Initialize pyedgar environment"],"metadata":{"id":"dQ6ztXzAZE6_"}},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W4Hhw2izU-jZ","executionInfo":{"status":"ok","timestamp":1747708342796,"user_tz":240,"elapsed":468,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"30dc3dbd-f722-4fde-8751-8224e068397a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Define and Create pyedgar Directory Structure\n","## Base directory\n","base_dir = '/content/drive/MyDrive/RA/Tech test/pyedgar'\n","\n","## Define subdirectories for config, index, and filings\n","conf_dir = os.path.join(base_dir, 'config')\n","index_dir = os.path.join(base_dir, 'indices')\n","filing_dir = os.path.join(base_dir, 'filings')\n","\n","## Create the directories if they don't exist\n","os.makedirs(conf_dir, exist_ok=True)\n","os.makedirs(index_dir, exist_ok=True)\n","os.makedirs(filing_dir, exist_ok=True)"],"metadata":{"id":"--trIomhXLxD","executionInfo":{"status":"ok","timestamp":1747708342864,"user_tz":240,"elapsed":54,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Create config file\n","conf_path = os.path.join(conf_dir, 'hades.colab.pyedgar.conf')\n","\n","with open(conf_path, 'w') as config_file:\n","    config_file.write(f\"\"\"\n","[DEFAULT]\n","SEC_BASE_URL = https://www.sec.gov\n","HEADERS = Sarah Fan (yichun.fan@gwmail.gwu.edu)\n","\n","[Paths]\n","INDEX_ROOT = {index_dir}\n","FILING_ROOT = {filing_dir}\n","\n","[Index]\n","INDEX_DELIMITER = |\n","INDEX_EXTENSION = idx\n","\n","[Downloader]\n","KEEP_ALL = False\n","\"\"\")\n","\n","# Set Environment Variable\n","os.environ['PYEDGAR_CONF'] = conf_path"],"metadata":{"id":"D-bMkF_VX9b-","executionInfo":{"status":"ok","timestamp":1747708342872,"user_tz":240,"elapsed":8,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# !pip install pyedgar"],"metadata":{"id":"SIBEESBXVIYg","executionInfo":{"status":"ok","timestamp":1747708342873,"user_tz":240,"elapsed":2,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from pyedgar import config, Filing, EDGARIndex\n","print(\"✅ pyedgar is using config file from:\", config.CONFIG_FILE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2o8ktcP3fIyY","executionInfo":{"status":"ok","timestamp":1747708344711,"user_tz":240,"elapsed":1839,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"2d9d9836-d870-4f4f-982f-bcdb5dd6496c"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ pyedgar is using config file from: /content/drive/MyDrive/RA/Tech test/pyedgar/config/hades.colab.pyedgar.conf\n"]}]},{"cell_type":"markdown","source":["## EDGAR data extraction"],"metadata":{"id":"ZpB9hA6XZMlW"}},{"cell_type":"markdown","source":["### 10-K index input"],"metadata":{"id":"xgR0UnecRWa_"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"YqXrrFVSQstZ","executionInfo":{"status":"ok","timestamp":1747708346155,"user_tz":240,"elapsed":50,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"outputs":[],"source":["import pandas as pd\n","import re\n","from time import sleep\n","from datetime import datetime\n","from bs4 import BeautifulSoup\n","from dateutil import parser"]},{"cell_type":"code","source":["# Load input file\n","df_input = pd.read_csv(\"/content/drive/MyDrive/RA/Tech test/rasamplemini_rfdtitle.csv\")\n","\n","# Ensure CIK is 10-digit zero-padded (required by EDGARIndex)\n","df_input['cik'] = df_input['cik'].astype(str).str.zfill(10)\n","df_input['filingyear'] = df_input['filingyear'].astype(int)\n","\n","# Load EDGAR index (use cached data if available)\n","idx = EDGARIndex(force_download=False)"],"metadata":{"id":"yv8-XBRfU3T5","executionInfo":{"status":"ok","timestamp":1747708346157,"user_tz":240,"elapsed":0,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["idx.indices"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yESlU3Y7GsOi","executionInfo":{"status":"ok","timestamp":1747708346161,"user_tz":240,"elapsed":3,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"2a02e096-0ebe-4d10-e41f-6deee3d3c5f9"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'form_10-K.idx': '/content/drive/MyDrive/RA/Tech test/pyedgar/indices/form_10-K.idx'}"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["index_10k = pd.read_csv('/content/drive/MyDrive/RA/Tech test/pyedgar/indices/form_10-K.idx',\n","                        sep='|', dtype=str, low_memory=False)\n","index_10k['cik'] = index_10k['CIK'].astype(str).str.zfill(10)\n","index_10k['filingyear'] = pd.to_datetime(index_10k['Date Filed'], errors='coerce').dt.year\n","index_10k.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"UI4T7QKzcvU3","executionInfo":{"status":"ok","timestamp":1747708348609,"user_tz":240,"elapsed":2441,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"82d899d6-689d-467f-9376-228afadf8aac"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  CIK              Company Name Form Type  Date Filed             Accession  \\\n","0  20  K TRON INTERNATIONAL INC      10-K  1996-03-28  0000893220-96-000500   \n","1  20  K TRON INTERNATIONAL INC      10-K  1997-03-19  0000893220-97-000572   \n","2  20  K TRON INTERNATIONAL INC   10-K405  1998-03-18  0000893220-98-000560   \n","3  20  K TRON INTERNATIONAL INC      10-K  1999-03-23  0000893220-99-000357   \n","4  20  K TRON INTERNATIONAL INC   10-K405  2000-03-30  0000893220-00-000394   \n","\n","          cik  filingyear  \n","0  0000000020        1996  \n","1  0000000020        1997  \n","2  0000000020        1998  \n","3  0000000020        1999  \n","4  0000000020        2000  "],"text/html":["\n","  <div id=\"df-26e817d7-8e57-4ac4-931f-cc2a10f8adaf\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>CIK</th>\n","      <th>Company Name</th>\n","      <th>Form Type</th>\n","      <th>Date Filed</th>\n","      <th>Accession</th>\n","      <th>cik</th>\n","      <th>filingyear</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>20</td>\n","      <td>K TRON INTERNATIONAL INC</td>\n","      <td>10-K</td>\n","      <td>1996-03-28</td>\n","      <td>0000893220-96-000500</td>\n","      <td>0000000020</td>\n","      <td>1996</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20</td>\n","      <td>K TRON INTERNATIONAL INC</td>\n","      <td>10-K</td>\n","      <td>1997-03-19</td>\n","      <td>0000893220-97-000572</td>\n","      <td>0000000020</td>\n","      <td>1997</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>20</td>\n","      <td>K TRON INTERNATIONAL INC</td>\n","      <td>10-K405</td>\n","      <td>1998-03-18</td>\n","      <td>0000893220-98-000560</td>\n","      <td>0000000020</td>\n","      <td>1998</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>20</td>\n","      <td>K TRON INTERNATIONAL INC</td>\n","      <td>10-K</td>\n","      <td>1999-03-23</td>\n","      <td>0000893220-99-000357</td>\n","      <td>0000000020</td>\n","      <td>1999</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20</td>\n","      <td>K TRON INTERNATIONAL INC</td>\n","      <td>10-K405</td>\n","      <td>2000-03-30</td>\n","      <td>0000893220-00-000394</td>\n","      <td>0000000020</td>\n","      <td>2000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26e817d7-8e57-4ac4-931f-cc2a10f8adaf')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-26e817d7-8e57-4ac4-931f-cc2a10f8adaf button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-26e817d7-8e57-4ac4-931f-cc2a10f8adaf');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-db7b6b1c-0713-4a5e-8f7f-9c3654e0c688\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db7b6b1c-0713-4a5e-8f7f-9c3654e0c688')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-db7b6b1c-0713-4a5e-8f7f-9c3654e0c688 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"index_10k"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["### 10-K index check"],"metadata":{"id":"FN-XVmC0yqzY"}},{"cell_type":"code","source":["# Merge to check which targets are matched in the 10-K index\n","check = df_input.merge(\n","    index_10k[['cik', 'filingyear', 'Accession']],\n","    on=['cik', 'filingyear'],\n","    how='left',\n","    indicator=True\n",")\n","\n","# Print summary\n","n_total = len(df_input)\n","n_matched = (check['_merge'] == 'both').sum()\n","n_missing = (check['_merge'] == 'left_only').sum()\n","\n","print(f\"Total CIK-year pairs: {n_total}\")\n","print(f\"Matched in 10-K index: {n_matched}\")\n","print(f\"Missing in 10-K index: {n_missing}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"stLZo9gEvJop","executionInfo":{"status":"ok","timestamp":1747708349333,"user_tz":240,"elapsed":696,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"24fd7199-5cd8-4708-ee9a-26aeb216fca4"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Total CIK-year pairs: 30\n","Matched in 10-K index: 36\n","Missing in 10-K index: 0\n"]}]},{"cell_type":"code","source":["# Count how many unique 10-K accessions exist for each (cik, filingyear) pair\n","dupes = check[check['_merge'] == 'both'] \\\n","    .groupby(['cik', 'filingyear'])['Accession'] \\\n","    .nunique() \\\n","    .reset_index()\n","\n","# Keep only those cik+filingyear pairs with more than one 10-K accession\n","dupes = dupes[dupes['Accession'] > 1]\n","\n","print(f\"Number of company/year pairs with multiple 10-Ks: {len(dupes)}\")\n","print(dupes)\n","\n","# Optionally: List all accessions for these cik+year pairs for inspection\n","if not dupes.empty:\n","    # Merge with original data to display all matching accessions\n","    details = check.merge(dupes[['cik', 'filingyear']], on=['cik', 'filingyear'], how='inner')\n","    print(\"\\nDetailed duplicate records:\")\n","    print(details[['cik', 'filingyear', 'Accession']].sort_values(['cik', 'filingyear']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHJEfAt7w8o4","executionInfo":{"status":"ok","timestamp":1747708349452,"user_tz":240,"elapsed":108,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"b4cb0c31-bc8b-4f8f-90a3-b6d2a6b8a03e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of company/year pairs with multiple 10-Ks: 6\n","           cik  filingyear  Accession\n","8   0000002034        2017          2\n","12  0000003116        2013          2\n","14  0000003116        2015          2\n","17  0000004962        2012          2\n","25  0000006201        2006          2\n","26  0000006201        2007          2\n","\n","Detailed duplicate records:\n","           cik  filingyear             Accession\n","0   0000002034        2017  0001144204-17-045100\n","1   0000002034        2017  0001144204-17-057835\n","4   0000003116        2013  0001157523-13-001183\n","5   0000003116        2013  0001157523-13-001479\n","2   0000003116        2015  0001171843-15-001465\n","3   0000003116        2015  0001171843-15-002393\n","6   0000004962        2012  0001193125-12-077400\n","7   0000004962        2012  0001140361-12-011832\n","10  0000006201        2006  0000950134-06-003715\n","11  0000006201        2006  0000006201-06-000049\n","8   0000006201        2007  0000950134-07-003888\n","9   0000006201        2007  0000950134-07-004263\n"]}]},{"cell_type":"markdown","source":["Based on the results above, manual inspection confirms that all duplicate records are due to amended filings (such as revised or supplemental reports). For subsequent analysis, we will use the most recent version, specifically the “FORM 10-K/A” filings, for each CIK-year pair where duplicates exist."],"metadata":{"id":"P3EzA3GLx4Qb"}},{"cell_type":"markdown","source":["**[Revised notes]** During the extraction process, I observed that most 10-K/A filings do not modify the Item 1A Risk Factors section. As a result, I have decided to extract this section from the original 10-K filings instead, in order to streamline processing and ensure greater consistency across documents."],"metadata":{"id":"gRVaycpBst5H"}},{"cell_type":"code","source":["# Keep only target cik + filingyear pairs from your input list\n","targets = df_input[['cik', 'filingyear']].drop_duplicates()\n","\n","# Merge all 10-K index entries with the target cik + filingyear pairs\n","merged = index_10k.merge(targets, on=['cik', 'filingyear'], how='inner')\n","\n","# Convert Date Filed to datetime format\n","merged['Date Filed'] = pd.to_datetime(merged['Date Filed'], errors='coerce')\n","\n","# Filter to keep only original 10-K filings (ignore 10-K/A)\n","merged = merged[merged['Form Type'] == '10-K']\n","\n","# Sort by cik, filingyear, Date Filed (ascending), and Accession (ascending)\n","merged = merged.sort_values(['cik', 'filingyear', 'Date Filed', 'Accession'])\n","\n","# For each (cik, filingyear) group, keep only the latest record (last one in the sorted group)\n","latest_10k = merged.groupby(['cik', 'filingyear'], as_index=False).last()\n","\n","# Display the selected records: one most recent 10-K per cik and year\n","print(latest_10k[['cik', 'filingyear', 'Accession', 'Date Filed', 'Form Type']])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mvGt2_kc1cNs","executionInfo":{"status":"ok","timestamp":1747708349794,"user_tz":240,"elapsed":344,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"6a27b05b-59ba-4743-d1e5-19f71a359640"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["           cik  filingyear             Accession Date Filed Form Type\n","0   0000001750        2016  0001047469-16-014299 2016-07-13      10-K\n","1   0000001750        2017  0001047469-17-004528 2017-07-12      10-K\n","2   0000001750        2018  0001047469-18-004978 2018-07-11      10-K\n","3   0000001800        2015  0001047469-15-001377 2015-02-27      10-K\n","4   0000001800        2016  0001047469-16-010246 2016-02-19      10-K\n","5   0000001800        2017  0001047469-17-000744 2017-02-17      10-K\n","6   0000002034        2015  0001571049-15-007509 2015-09-11      10-K\n","7   0000002034        2016  0001571049-16-017785 2016-08-26      10-K\n","8   0000002034        2017  0001144204-17-045100 2017-08-25      10-K\n","9   0000002488        2008  0001193125-08-038588 2008-02-26      10-K\n","10  0000002488        2009  0001193125-09-036235 2009-02-24      10-K\n","11  0000002488        2010  0001193125-10-035218 2010-02-19      10-K\n","12  0000003116        2013  0001157523-13-001183 2013-03-01      10-K\n","13  0000003116        2014  0001157523-14-001078 2014-03-14      10-K\n","14  0000003116        2015  0001171843-15-001465 2015-03-17      10-K\n","15  0000004962        2010  0001193125-10-041232 2010-02-26      10-K\n","16  0000004962        2011  0000950123-11-019072 2011-02-28      10-K\n","17  0000004962        2012  0001193125-12-077400 2012-02-24      10-K\n","18  0000004977        2007  0001104659-07-015014 2007-02-28      10-K\n","19  0000004977        2008  0000950144-08-001495 2008-02-29      10-K\n","20  0000004977        2009  0000950144-09-001463 2009-02-20      10-K\n","21  0000005768        2007  0001104659-07-047514 2007-06-13      10-K\n","22  0000005768        2008  0001104659-08-039830 2008-06-13      10-K\n","23  0000005768        2009  0001104659-09-038109 2009-06-15      10-K\n","24  0000006201        2005  0000950134-05-003726 2005-02-25      10-K\n","25  0000006201        2006  0000950134-06-003715 2006-02-24      10-K\n","26  0000006201        2007  0000950134-07-003888 2007-02-23      10-K\n","27  0000006720        2005  0001193125-05-052635 2005-03-16      10-K\n","28  0000006720        2006  0001193125-06-056413 2006-03-16      10-K\n","29  0000006720        2007  0001193125-07-056201 2007-03-16      10-K\n"]}]},{"cell_type":"markdown","source":["### Functions"],"metadata":{"id":"Jhbhf5NlI0eK"}},{"cell_type":"markdown","source":["#### Extraciton for reporting date\n"],"metadata":{"id":"uaA2X-KQ42EY"}},{"cell_type":"code","source":["def extract_reporting_date_from_html(html, maxlen=6000):\n","    html_head = html[:maxlen]\n","    html_head = html_head.replace('&nbsp;', ' ').replace('&#160;', ' ').replace('\\xa0', ' ')\n","\n","    # Step 1: Look directly in HTML for the date pattern\n","    m = re.search(\n","        r'(?i)for\\s+(?:the\\s+)?(?:fiscal\\s+)?year\\s+ended\\s+([A-Za-z]{3,10})\\s*\\.?\\s*(\\d{1,2}),?\\s*(\\d{4})',\n","        html_head\n","    )\n","    if m:\n","        # Combine month, day, year\n","        date_str = f\"{m.group(1)} {m.group(2)}, {m.group(3)}\"\n","        try:\n","            dt = parser.parse(date_str)\n","            return dt.strftime(\"%Y/%m/%d\")\n","        except Exception as e:\n","            print(\"❌ Failed to parse:\", date_str, \"| Error:\", e)\n","\n","    # Step 2: Fallback to <PERIOD> tag\n","    m = re.search(r\"<PERIOD>(\\d{8})</PERIOD>\", html_head, re.IGNORECASE)\n","    if m:\n","        date = m.group(1)\n","        print(\"📄 Found <PERIOD>:\", date)\n","        return f\"{date[:4]}/{date[4:6]}/{date[6:]}\"\n","\n","    m = re.search(r\"PERIOD[=:\\s]+(\\d{8})\", html_head, re.IGNORECASE)\n","    if m:\n","        date = m.group(1)\n","        print(\"📄 Found PERIOD=:\", date)\n","        return f\"{date[:4]}/{date[4:6]}/{date[6:]}\"\n","\n","    print(f\"⚠️ No reporting date found for CIK={cik}, Year={year}\")\n","    return \"\""],"metadata":{"id":"DrIkB74kJeUt","executionInfo":{"status":"ok","timestamp":1747708350755,"user_tz":240,"elapsed":17,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["#### Extraction for risk factors section"],"metadata":{"id":"MTRuJ9OkJCd5"}},{"cell_type":"markdown","source":["In this version of the `extract_item_1a_section_from_html` function, all logging and fallback diagnostics have been removed. If the `Item 1A` section cannot be located using either a direct heading match or a split `<tr>` tag fallback, the function will simply return None without attempting additional heuristics.\n","\n","This is appropriate because the extraction process has already successfully identified the `Item 1A` section in `93.3%` of the filings (28 out of 30), leaving only two unmatched cases. Upon closer inspection, these two filings place their risk factor discussions under **ITEM 7. MANAGEMENT’S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS**, using inconsistent headings such as “*Risk Factors*” and “*Factors That Could Affect Future Results*”.\n","\n","\n","Due to the variation in formatting and the added complexity it would introduce to robustly detect such edge cases, this version of the function intentionally **does not handle them**. Addressing those special cases would require additional effort in title normalization or context-aware parsing, which falls outside the scope of the current streamlined extraction logic."],"metadata":{"id":"SXOLefNpUYgk"}},{"cell_type":"code","source":["def clean_html_tables(txt):\n","    soup = BeautifulSoup(txt, 'html.parser')\n","\n","    for table in soup.find_all('table'):\n","        table_text = table.get_text(\" \", strip=True).lower()\n","\n","        has_item_1a = bool(table.find('b', string=lambda s: s and 'item 1a' in s.lower()))\n","        has_risk_factors = bool(table.find('b', string=lambda s: s and 'risk factors' in s.lower()))\n","\n","        if has_item_1a and has_risk_factors:\n","            continue\n","\n","        if any(keyword in table_text for keyword in [\n","            'forward-looking statements', 'you are cautioned', 'undue reliance'\n","        ]):\n","            table.decompose()\n","\n","    return str(soup)"],"metadata":{"id":"rBcvwDjayV28","executionInfo":{"status":"ok","timestamp":1747708350828,"user_tz":240,"elapsed":67,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["def extract_item_1a_section_from_html(txt, cik=None, year=None):\n","    txt = txt.replace('&nbsp;', ' ').replace('&#160;', ' ').replace('\\xa0', ' ')\n","    txt = txt.replace('&#151;', 'nnn')\n","    txt = re.sub(r'<!-- XBRL Footnotes Begin -->(.*?)<!-- XBRL Footnotes End -->', '', txt, flags=re.DOTALL)\n","    txt = clean_html_tables(txt)\n","\n","    soup = BeautifulSoup(txt, 'html.parser')\n","\n","    found_header = None\n","\n","    for tag in soup.find_all('b'):\n","      text = tag.get_text(\" \", strip=True).lower()\n","\n","      if (\n","          \"item 1a\" in text\n","          and \"risk factors\" in text\n","          and not any(exclude in text for exclude in [\"see\", \"refer\", \"page\", \"discussion\", \"discussed\"])\n","      ):\n","        found_header = tag\n","        break\n","\n","    if found_header:\n","        print(f\"✅ Found structural header tag for CIK={cik}, Year={year}\")\n","\n","        header_text = found_header.get_text(\" \", strip=True)\n","        header_text_clean = re.escape(header_text[:80])\n","        header_match = re.search(header_text_clean, txt, flags=re.IGNORECASE)\n","\n","        if header_match:\n","            start_index = header_match.start()\n","            txt_trimmed = txt[start_index:]\n","\n","            end_match = re.search(r'item\\s+1b|item\\s+2', txt_trimmed, flags=re.IGNORECASE)\n","            end_index = end_match.start() if end_match else len(txt_trimmed)\n","\n","            section_text = txt_trimmed[:end_index]\n","\n","            if len(section_text.strip())<100:\n","              print(f\"⚠️ Ignored short Item 1A section (<100 chars) for CIK={cik}, Year={year}\")\n","              return None, None\n","\n","            return section_text, \"parsed-structural\"\n","\n","        else:\n","            print(f\"⚠️ Header found structurally but not located in raw HTML for CIK={cik}\")\n","\n","    # Fallback regex\n","    pattern = r'((?:^|[\\n>])\\s*item\\s*1a[\\.\\:]*((?!nnn).)*?risk\\s*factors.*?)(item\\s*1b|item\\s*2)'\n","    matches = re.findall(pattern, txt, flags=re.IGNORECASE | re.DOTALL | re.MULTILINE)\n","    if matches:\n","        print(f\"✅ Found Item 1A section for CIK={cik}, Year={year} (regex fallback)\")\n","        return max(matches, key=lambda x: len(x[0]))[0], \"regex-fallback\"\n","\n","    print(f\"❌ Item 1A section not found for CIK={cik}, Year={year}\")\n","    return None, None"],"metadata":{"id":"sOiNCWVqnjMk","executionInfo":{"status":"ok","timestamp":1747708350829,"user_tz":240,"elapsed":2,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def extract_item_1a_section_from_html(txt, cik=None, year=None):\n","    # Step 0: Normalize text and remove footnotes/tables\n","    txt = txt.replace('&nbsp;', ' ').replace('&#160;', ' ').replace('\\xa0', ' ')\n","    txt = txt.replace('&#151;', 'nnn')\n","    txt = re.sub(r'<!-- XBRL Footnotes Begin -->(.*?)<!-- XBRL Footnotes End -->', '', txt, flags=re.DOTALL)\n","    txt = clean_html_tables(txt)\n","\n","    soup = BeautifulSoup(txt, 'html.parser')\n","\n","    # Step 1: Structural match using <b> tags\n","    for tag in soup.find_all('b'):\n","        text = tag.get_text(\" \", strip=True).lower()\n","\n","        if (\n","            \"item 1a\" in text\n","            and \"risk factors\" in text\n","            and not any(exclude in text for exclude in [\"see\", \"refer\", \"page\", \"discussion\", \"discussed\"])\n","        ):\n","            header_text = tag.get_text(\" \", strip=True)\n","            header_text_clean = re.escape(header_text[:80])\n","            header_match = re.search(header_text_clean, txt, flags=re.IGNORECASE)\n","\n","            if header_match:\n","                start_index = header_match.start()\n","                txt_trimmed = txt[start_index:]\n","\n","                end_match = re.search(r'item\\s+1b|item\\s+2', txt_trimmed, flags=re.IGNORECASE)\n","                end_index = end_match.start() if end_match else len(txt_trimmed)\n","\n","                section_text = txt_trimmed[:end_index]\n","\n","                if len(section_text.strip()) >= 100:\n","                    print(f\"✅ Found valid structural Item 1A section for CIK={cik}, Year={year}\")\n","                    return section_text, \"parsed-structural\"\n","                else:\n","                    print(f\"⚠️ Skipped short Item 1A section (<100 chars) for CIK={cik}, Year={year}\")\n","                    continue  # try next candidate\n","\n","    # Step 2: Fallback regex\n","    pattern = r'((?:^|[\\n>])\\s*item\\s*1a[\\.\\:]*((?!nnn).)*?risk\\s*factors.*?)(item\\s*1b|item\\s*2)'\n","    matches = re.findall(pattern, txt, flags=re.IGNORECASE | re.DOTALL | re.MULTILINE)\n","\n","    if matches:\n","        best = max(matches, key=lambda x: len(x[0]))[0]\n","        if len(best.strip()) >= 100:\n","            print(f\"✅ Found Item 1A section for CIK={cik}, Year={year} (regex fallback)\")\n","            return best, \"regex-fallback\"\n","        else:\n","            print(f\"⚠️ Skipped short fallback Item 1A section (<100 chars) for CIK={cik}, Year={year}\")\n","\n","    print(f\"❌ Item 1A section not found for CIK={cik}, Year={year}\")\n","    return None, None"],"metadata":{"id":"VbQOTKLyhnPD","executionInfo":{"status":"ok","timestamp":1747708350903,"user_tz":240,"elapsed":48,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["#### Extraction for titles"],"metadata":{"id":"o6G0cU9S55_A"}},{"cell_type":"code","source":["def extract_risk_titles_from_item_1a_html(risk_html):\n","    if not risk_html:\n","        return []\n","\n","    soup = BeautifulSoup(risk_html, \"html.parser\")\n","    candidates = []\n","\n","    # Step 1: Tags with semantic emphasis\n","    for tag in soup.find_all(['b', 'i', 'u']):\n","        sub = tag.get_text(separator=' ', strip=True).replace('\\xa0', ' ').strip()\n","        if (\n","            sub\n","            and not re.search(r'item\\s*1a', sub, re.IGNORECASE)\n","            and not re.search(r'risk\\s*factors?', sub, re.IGNORECASE)\n","            and not sub.endswith(':')\n","            and not sub.isupper()\n","        ):\n","            candidates.append(sub)\n","\n","    # Step 2: Additional support for <font> or <div> with bold styles\n","    for tag in soup.find_all(['font', 'div']):\n","        style = tag.get('style', '').lower()\n","        if 'font-weight: bold' in style:\n","            sub = tag.get_text(separator=' ', strip=True).replace('\\xa0', ' ').strip()\n","            if (\n","                sub\n","                and not re.search(r'item\\s*1a', sub, re.IGNORECASE)\n","                and not re.search(r'risk\\s*factors?', sub, re.IGNORECASE)\n","                and not sub.endswith(':')\n","                and not sub.isupper()\n","            ):\n","                candidates.append(sub)\n","\n","    # Deduplicate while preserving order\n","    deduped = list(dict.fromkeys(candidates))\n","\n","    # Filter out very short titles (less than 10 characters)\n","    filtered = [title for title in deduped if len(title) >= 10]\n","\n","    print(f\"✅ Total risk factor titles found: {len(filtered)}\")\n","\n","    return filtered"],"metadata":{"id":"o7I_As7q59Nv","executionInfo":{"status":"ok","timestamp":1747708350904,"user_tz":240,"elapsed":10,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["### Extraction output"],"metadata":{"id":"Ns9FVwg9I9yB"}},{"cell_type":"markdown","source":["#### Reportingdate output check"],"metadata":{"id":"7tVogCqL10fH"}},{"cell_type":"code","source":["reporting_records = []\n","\n","for row in df_input.itertuples(index=False):\n","    cik = str(row.cik).zfill(10)\n","    year = int(row.filingyear)\n","\n","    df_cik_match = latest_10k[\n","        (latest_10k['CIK'].astype(str).str.zfill(10) == cik) &\n","        (pd.to_datetime(latest_10k['Date Filed']).dt.year == year)\n","    ]\n","    if df_cik_match.empty:\n","        continue\n","\n","    filing_meta = df_cik_match.iloc[0]\n","    accession = filing_meta['Accession'].split('/')[-1].replace('.txt', '')\n","    filingdate = filing_meta['Date Filed']\n","\n","    try:\n","        filing = Filing(cik=cik, accession=accession)\n","        text = filing.full_text\n","    except Exception as e:\n","        print(f\"⚠️ Failed to retrieve filing text for {cik}, {accession}: {e}\")\n","        continue\n","\n","    reportingdate = extract_reporting_date_from_html(text)\n","\n","    reporting_records.append({\n","        'cik': cik,\n","        'filingyear': year,\n","        'filingdate': filingdate,\n","        'reportingdate': reportingdate\n","    })\n","\n","df_reporting = pd.DataFrame(reporting_records)\n","print(df_reporting)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3--Am48J16Cj","executionInfo":{"status":"ok","timestamp":1747708360979,"user_tz":240,"elapsed":3764,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"656946ff-1927-45e6-9e76-ad346212e102"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["           cik  filingyear filingdate reportingdate\n","0   0000001750        2018 2018-07-11    2018/05/31\n","1   0000001750        2017 2017-07-12    2017/05/31\n","2   0000001750        2016 2016-07-13    2016/05/31\n","3   0000001800        2017 2017-02-17    2016/12/31\n","4   0000001800        2016 2016-02-19    2015/12/31\n","5   0000001800        2015 2015-02-27    2014/12/31\n","6   0000002034        2017 2017-08-25    2017/06/30\n","7   0000002034        2016 2016-08-26    2016/06/30\n","8   0000002034        2015 2015-09-11    2015/06/30\n","9   0000002488        2010 2010-02-19    2009/12/26\n","10  0000002488        2009 2009-02-24    2008/12/27\n","11  0000002488        2008 2008-02-26    2007/12/29\n","12  0000003116        2015 2015-03-17    2014/12/31\n","13  0000003116        2014 2014-03-14    2013/12/31\n","14  0000003116        2013 2013-03-01    2012/12/31\n","15  0000004962        2012 2012-02-24    2011/12/31\n","16  0000004962        2011 2011-02-28    2010/12/31\n","17  0000004962        2010 2010-02-26    2009/12/31\n","18  0000004977        2009 2009-02-20    2008/12/31\n","19  0000004977        2008 2008-02-29    2007/12/31\n","20  0000004977        2007 2007-02-28    2006/12/31\n","21  0000005768        2009 2009-06-15    2009/03/31\n","22  0000005768        2008 2008-06-13    2008/03/31\n","23  0000005768        2007 2007-06-13    2007/03/31\n","24  0000006201        2007 2007-02-23    2006/12/31\n","25  0000006201        2006 2006-02-24    2005/12/31\n","26  0000006201        2005 2005-02-25    2004/12/31\n","27  0000006720        2007 2007-03-16    2006/12/31\n","28  0000006720        2006 2006-03-16    2005/12/31\n","29  0000006720        2005 2005-03-16    2004/12/31\n"]}]},{"cell_type":"markdown","source":["#### Risk factors section check"],"metadata":{"id":"Utd82CDg28s5"}},{"cell_type":"code","source":["item1a_check = []\n","\n","for row in df_reporting.itertuples(index=False):\n","    cik = str(row.cik).zfill(10)\n","    year = int(row.filingyear)\n","    filingdate = row.filingdate\n","\n","    df_cik_match = latest_10k[\n","        (latest_10k['CIK'].astype(str).str.zfill(10) == cik) &\n","        (pd.to_datetime(latest_10k['Date Filed']).dt.year == year)\n","    ]\n","    if df_cik_match.empty:\n","        continue\n","\n","    accession = df_cik_match.iloc[0]['Accession'].split('/')[-1].replace('.txt', '')\n","\n","    try:\n","        filing = Filing(cik=cik, accession=accession)\n","        text = filing.full_text\n","    except Exception as e:\n","        print(f\"⚠️ Failed to retrieve filing text for {cik}, {accession}: {e}\")\n","        continue\n","\n","    # Step 1A: check for presence of Item 1A block\n","    risk_html, source = extract_item_1a_section_from_html(text, cik=cik, year=year)\n","    status = \"✅ Found\" if risk_html else \"❌ Not found\"\n","\n","    item1a_check.append({\n","        'cik': cik,\n","        'filingyear': year,\n","        'filingdate': filingdate,\n","        'item_1a_found': status\n","    })\n","\n","df_check = pd.DataFrame(item1a_check)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i4iZkxrj6XtC","executionInfo":{"status":"ok","timestamp":1747708729669,"user_tz":240,"elapsed":363520,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"fc86006a-44e6-4ebd-cc07-4acad389f303"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Found valid structural Item 1A section for CIK=0000001750, Year=2018\n","✅ Found valid structural Item 1A section for CIK=0000001750, Year=2017\n","✅ Found valid structural Item 1A section for CIK=0000001750, Year=2016\n","✅ Found valid structural Item 1A section for CIK=0000001800, Year=2017\n","✅ Found valid structural Item 1A section for CIK=0000001800, Year=2016\n","✅ Found valid structural Item 1A section for CIK=0000001800, Year=2015\n","✅ Found valid structural Item 1A section for CIK=0000002034, Year=2017\n","✅ Found valid structural Item 1A section for CIK=0000002034, Year=2016\n","✅ Found Item 1A section for CIK=0000002034, Year=2015 (regex fallback)\n","✅ Found Item 1A section for CIK=0000002488, Year=2010 (regex fallback)\n","✅ Found Item 1A section for CIK=0000002488, Year=2009 (regex fallback)\n","✅ Found Item 1A section for CIK=0000002488, Year=2008 (regex fallback)\n","✅ Found Item 1A section for CIK=0000003116, Year=2015 (regex fallback)\n","✅ Found Item 1A section for CIK=0000003116, Year=2014 (regex fallback)\n","✅ Found Item 1A section for CIK=0000003116, Year=2013 (regex fallback)\n","✅ Found Item 1A section for CIK=0000004962, Year=2012 (regex fallback)\n","✅ Found Item 1A section for CIK=0000004962, Year=2011 (regex fallback)\n","✅ Found Item 1A section for CIK=0000004962, Year=2010 (regex fallback)\n","✅ Found valid structural Item 1A section for CIK=0000004977, Year=2009\n","✅ Found Item 1A section for CIK=0000004977, Year=2008 (regex fallback)\n","✅ Found Item 1A section for CIK=0000004977, Year=2007 (regex fallback)\n","✅ Found Item 1A section for CIK=0000005768, Year=2009 (regex fallback)\n","✅ Found Item 1A section for CIK=0000005768, Year=2008 (regex fallback)\n","✅ Found valid structural Item 1A section for CIK=0000005768, Year=2007\n","⚠️ Skipped short Item 1A section (<100 chars) for CIK=0000006201, Year=2007\n","✅ Found Item 1A section for CIK=0000006201, Year=2007 (regex fallback)\n","⚠️ Skipped short Item 1A section (<100 chars) for CIK=0000006201, Year=2006\n","✅ Found Item 1A section for CIK=0000006201, Year=2006 (regex fallback)\n","❌ Item 1A section not found for CIK=0000006201, Year=2005\n","✅ Found valid structural Item 1A section for CIK=0000006720, Year=2007\n","✅ Found valid structural Item 1A section for CIK=0000006720, Year=2006\n","❌ Item 1A section not found for CIK=0000006720, Year=2005\n"]}]},{"cell_type":"code","source":["\"\"\"Risk factors content check\n","\n","from itertools import islice\n","\n","for row in islice(df_reporting.itertuples(index=False), 24,25):\n","    cik = str(row.cik).zfill(10)\n","    year = int(row.filingyear)\n","\n","    df_cik_match = latest_10k[\n","        (latest_10k['CIK'].astype(str).str.zfill(10) == cik) &\n","        (pd.to_datetime(latest_10k['Date Filed']).dt.year == year)\n","    ]\n","    if df_cik_match.empty:\n","        continue\n","\n","    accession = df_cik_match.iloc[0]['Accession'].split('/')[-1].replace('.txt', '')\n","    try:\n","        filing = Filing(cik=cik, accession=accession)\n","        text = filing.full_text\n","    except Exception as e:\n","        print(f\"⚠️ Failed to retrieve filing for {cik}: {e}\")\n","        continue\n","\n","    section, source = extract_item_1a_section_from_html(text, cik=cik, year=year)\n","\n","    if section:\n","        print(f\"\\n🎯 First matched Item 1A section for CIK={cik}, Year={year}\")\n","        print(\"📌 Source:\", source)\n","        print(\"📄 Section Preview:\\n\")\n","        print(section[:1500])\n","        break\n","\"\"\""],"metadata":{"id":"nRBbP7MlkvO0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Risk titles output"],"metadata":{"id":"tTa7n2W46TYv"}},{"cell_type":"code","source":["rfd_records = []\n","\n","for row in df_reporting.itertuples(index=False):\n","    cik = str(row.cik).zfill(10)\n","    year = int(row.filingyear)\n","    filingdate = row.filingdate\n","\n","    df_cik_match = latest_10k[\n","        (latest_10k['CIK'].astype(str).str.zfill(10) == cik) &\n","        (pd.to_datetime(latest_10k['Date Filed']).dt.year == year)\n","    ]\n","    if df_cik_match.empty:\n","        continue\n","\n","    accession = df_cik_match.iloc[0]['Accession'].split('/')[-1].replace('.txt', '')\n","\n","    try:\n","        filing = Filing(cik=cik, accession=accession)\n","        text = filing.full_text\n","    except Exception:\n","        print(f\"⚠️ Failed to load filing for CIK={cik}, Accession={accession}\")\n","        continue\n","\n","    risk_html, source = extract_item_1a_section_from_html(text, cik=cik, year=year)\n","\n","    if not risk_html:\n","        continue\n","\n","    risk_titles = extract_risk_titles_from_item_1a_html(risk_html)\n","\n","    if not risk_titles:\n","        risk_titles = ['']\n","\n","    for title in risk_titles:\n","        rfd_records.append({\n","            'cik': cik,\n","            'filingyear': year,\n","            'filingdate': filingdate,\n","            'RFDTitle': title.strip()\n","        })\n","\n","df_rfd = pd.DataFrame(rfd_records)\n","print(df_rfd)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6rCHeHJsQLA","executionInfo":{"status":"ok","timestamp":1747709079042,"user_tz":240,"elapsed":349372,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"4f363cfc-0428-44fa-f869-937af0febe13"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Found valid structural Item 1A section for CIK=0000001750, Year=2018\n","✅ Total risk factor titles found: 18\n","✅ Found valid structural Item 1A section for CIK=0000001750, Year=2017\n","✅ Total risk factor titles found: 19\n","✅ Found valid structural Item 1A section for CIK=0000001750, Year=2016\n","✅ Total risk factor titles found: 19\n","✅ Found valid structural Item 1A section for CIK=0000001800, Year=2017\n","✅ Total risk factor titles found: 20\n","✅ Found valid structural Item 1A section for CIK=0000001800, Year=2016\n","✅ Total risk factor titles found: 19\n","✅ Found valid structural Item 1A section for CIK=0000001800, Year=2015\n","✅ Total risk factor titles found: 19\n","✅ Found valid structural Item 1A section for CIK=0000002034, Year=2017\n","✅ Total risk factor titles found: 64\n","✅ Found valid structural Item 1A section for CIK=0000002034, Year=2016\n","✅ Total risk factor titles found: 57\n","✅ Found Item 1A section for CIK=0000002034, Year=2015 (regex fallback)\n","✅ Total risk factor titles found: 49\n","✅ Found Item 1A section for CIK=0000002488, Year=2010 (regex fallback)\n","✅ Total risk factor titles found: 43\n","✅ Found Item 1A section for CIK=0000002488, Year=2009 (regex fallback)\n","✅ Total risk factor titles found: 44\n","✅ Found Item 1A section for CIK=0000002488, Year=2008 (regex fallback)\n","✅ Total risk factor titles found: 47\n","✅ Found Item 1A section for CIK=0000003116, Year=2015 (regex fallback)\n","✅ Total risk factor titles found: 55\n","✅ Found Item 1A section for CIK=0000003116, Year=2014 (regex fallback)\n","✅ Total risk factor titles found: 53\n","✅ Found Item 1A section for CIK=0000003116, Year=2013 (regex fallback)\n","✅ Total risk factor titles found: 52\n","✅ Found Item 1A section for CIK=0000004962, Year=2012 (regex fallback)\n","✅ Total risk factor titles found: 35\n","✅ Found Item 1A section for CIK=0000004962, Year=2011 (regex fallback)\n","✅ Total risk factor titles found: 35\n","✅ Found Item 1A section for CIK=0000004962, Year=2010 (regex fallback)\n","✅ Total risk factor titles found: 31\n","✅ Found valid structural Item 1A section for CIK=0000004977, Year=2009\n","✅ Total risk factor titles found: 27\n","✅ Found Item 1A section for CIK=0000004977, Year=2008 (regex fallback)\n","✅ Total risk factor titles found: 15\n","✅ Found Item 1A section for CIK=0000004977, Year=2007 (regex fallback)\n","✅ Total risk factor titles found: 15\n","✅ Found Item 1A section for CIK=0000005768, Year=2009 (regex fallback)\n","✅ Total risk factor titles found: 21\n","✅ Found Item 1A section for CIK=0000005768, Year=2008 (regex fallback)\n","✅ Total risk factor titles found: 20\n","✅ Found valid structural Item 1A section for CIK=0000005768, Year=2007\n","✅ Total risk factor titles found: 20\n","⚠️ Skipped short Item 1A section (<100 chars) for CIK=0000006201, Year=2007\n","✅ Found Item 1A section for CIK=0000006201, Year=2007 (regex fallback)\n","✅ Total risk factor titles found: 20\n","⚠️ Skipped short Item 1A section (<100 chars) for CIK=0000006201, Year=2006\n","✅ Found Item 1A section for CIK=0000006201, Year=2006 (regex fallback)\n","✅ Total risk factor titles found: 19\n","❌ Item 1A section not found for CIK=0000006201, Year=2005\n","✅ Found valid structural Item 1A section for CIK=0000006720, Year=2007\n","✅ Total risk factor titles found: 19\n","✅ Found valid structural Item 1A section for CIK=0000006720, Year=2006\n","✅ Total risk factor titles found: 16\n","❌ Item 1A section not found for CIK=0000006720, Year=2005\n","            cik  filingyear filingdate  \\\n","0    0000001750        2018 2018-07-11   \n","1    0000001750        2018 2018-07-11   \n","2    0000001750        2018 2018-07-11   \n","3    0000001750        2018 2018-07-11   \n","4    0000001750        2018 2018-07-11   \n","..          ...         ...        ...   \n","866  0000006720        2006 2006-03-16   \n","867  0000006720        2006 2006-03-16   \n","868  0000006720        2006 2006-03-16   \n","869  0000006720        2006 2006-03-16   \n","870  0000006720        2006 2006-03-16   \n","\n","                                              RFDTitle  \n","0    We are affected by factors that adversely impa...  \n","1    Our U.S. government contracts may not continue...  \n","2    We face risks of cost overruns and losses on f...  \n","3    Success at our airframe maintenance facilities...  \n","4    We operate in highly competitive markets, and ...  \n","..                                                 ...  \n","866  Changes in currency exchange rates could affec...  \n","867  Acts of war or terrorism may have an adverse e...  \n","868  K2 is subject to and may incur liabilities und...  \n","869  Unfavorable weather can adversely affect K2’s ...  \n","870  K2 is subject to and may incur liabilities und...  \n","\n","[871 rows x 4 columns]\n"]}]},{"cell_type":"code","source":["\"\"\"\n","from itertools import islice\n","\n","rfd_records = []\n","\n","for row in islice(df_reporting.itertuples(index=False), 25,26):\n","    cik = str(row.cik).zfill(10)\n","    year = int(row.filingyear)\n","    filingdate = row.filingdate\n","\n","    df_cik_match = latest_10k[\n","        (latest_10k['CIK'].astype(str).str.zfill(10) == cik) &\n","        (pd.to_datetime(latest_10k['Date Filed']).dt.year == year)\n","    ]\n","    if df_cik_match.empty:\n","        continue\n","\n","    accession = df_cik_match.iloc[0]['Accession'].split('/')[-1].replace('.txt', '')\n","\n","    try:\n","        filing = Filing(cik=cik, accession=accession)\n","        text = filing.full_text\n","    except Exception:\n","        print(f\"⚠️ Failed to load filing for CIK={cik}, Accession={accession}\")\n","        continue\n","\n","    risk_html, source = extract_item_1a_section_from_html(text, cik=cik, year=year)\n","\n","    if not risk_html:\n","        continue\n","\n","    risk_titles = extract_risk_titles_from_item_1a_html(risk_html)\n","\n","    if not risk_titles:\n","        risk_titles = ['']\n","\n","    for title in risk_titles:\n","        rfd_records.append({\n","            'cik': cik,\n","            'filingyear': year,\n","            'filingdate': filingdate,\n","            'RFDTitle': title.strip()\n","        })\n","\n","df_rfd = pd.DataFrame(rfd_records)\n","print(df_rfd)\n","\"\"\""],"metadata":{"id":"2VrSwSw76YLi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Final output"],"metadata":{"id":"ANvaZT6S6RpD"}},{"cell_type":"code","source":["df_output = df_reporting.merge(\n","    df_rfd[['cik', 'filingyear', 'RFDTitle']],\n","    on=['cik', 'filingyear'],\n","    how='left'\n",")\n","\n","print(df_output.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7NOrtJiPrxn0","executionInfo":{"status":"ok","timestamp":1747709079054,"user_tz":240,"elapsed":9,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}},"outputId":"123a974c-0749-42bb-f2e3-ede3eb8de7f2"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["          cik  filingyear filingdate reportingdate  \\\n","0  0000001750        2018 2018-07-11    2018/05/31   \n","1  0000001750        2018 2018-07-11    2018/05/31   \n","2  0000001750        2018 2018-07-11    2018/05/31   \n","3  0000001750        2018 2018-07-11    2018/05/31   \n","4  0000001750        2018 2018-07-11    2018/05/31   \n","\n","                                            RFDTitle  \n","0  We are affected by factors that adversely impa...  \n","1  Our U.S. government contracts may not continue...  \n","2  We face risks of cost overruns and losses on f...  \n","3  Success at our airframe maintenance facilities...  \n","4  We operate in highly competitive markets, and ...  \n"]}]},{"cell_type":"code","source":["df_output.to_csv('rasamplemini_rfdtitle_Sarahoutput.csv', index=False)"],"metadata":{"id":"aZVzsymRnxuM","executionInfo":{"status":"ok","timestamp":1747709079064,"user_tz":240,"elapsed":8,"user":{"displayName":"Yichun Fan","userId":"18013003337662362965"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## Reference"],"metadata":{"id":"z5AxLnB62C5k"}},{"cell_type":"markdown","source":["Campbell, J. L., Chen, H., Dhaliwal, D. S., Lu, H. M., & Steele, L. B. (2014). The information content of mandatory risk factor disclosures in corporate filings. *Review of Accounting Studies, 19*(1), 396–455.\n","\n","Gaulin, M. P. (2017). *Risk fact or fiction: The information content of risk factor disclosures* (Doctoral dissertation, Rice University).\n"],"metadata":{"id":"2O61f9ZH2EqS"}}]}